{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skip bigram are filled into the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = [line.strip().split('\\t') for line in open('citeseerx.ngms','r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "skipBigramDistance = defaultdict(lambda:defaultdict(Counter))\n",
    "# skipBigramExample = defaultdict(lambda: Counter)\n",
    "\n",
    "def read_ngrams(raw_data):\n",
    "    for sentence, freq in raw_data:\n",
    "        ngram = sentence.split(' ')\n",
    "        count = int(freq)\n",
    "        skipBigramDistance[ngram[0]][ngram[-1]] += Counter({len(ngram)-1: count})\n",
    "        skipBigramDistance[ngram[-1]][ngram[0]] += Counter({1-len(ngram): count}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_ngrams(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('in-prep',\n",
      "  Counter({1: 62342,\n",
      "           3: 2192,\n",
      "           -2: 859,\n",
      "           4: 422,\n",
      "           2: 355,\n",
      "           -3: 298,\n",
      "           -4: 281,\n",
      "           -5: 132,\n",
      "           -1: 108})),\n",
      " ('play-v',\n",
      "  Counter({-3: 41994,\n",
      "           -2: 13098,\n",
      "           1: 2523,\n",
      "           -4: 1687,\n",
      "           2: 1317,\n",
      "           -1: 287,\n",
      "           3: 23,\n",
      "           -5: 22})),\n",
      " ('important-adj', Counter({-1: 23675, -2: 142}))]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(sorted(list(skipBigramDistance['role-n'].items()),key=lambda x: -sum(x[1].values()))[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-5, 22), (-4, 1687), (-3, 41994), (-2, 13098), (-1, 287), (1, 2523), (2, 1317), (3, 23)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(list(skipBigramDistance['role-n']['play-v'].items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter by λ1 and λ3 filtering parameter for collocates and positions\n",
    "- λ1: strength of wi, ki = (freqi − freq)/σ > λ1\n",
    "- λ3: in pi peak frequency of j such that pij > avg(pi) + λ3*Vi^(1/2)\n",
    "<br>[Vi : 在 pi 中 所有數的標準差]\n",
    "<br>Smadja (1993) suggested using the setting of (λ1, λ2, λ3) = (1, 10, 1) for better results.\n",
    "<br>\n",
    "變異數 Vi sigma^2 開更號 = 標準差\n",
    "![Alt text](SD.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import akl as a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "skip_bigram_abc = defaultdict(lambda: 0)\n",
    "\n",
    "max_distance = 5\n",
    "\n",
    "for word, vals in skipBigramDistance.items():\n",
    "    count = []\n",
    "    if word in a.akl:\n",
    "        for coll, val in vals.items():\n",
    "            c = val.values()\n",
    "            c_bar = sum(c) / (2*max_distance)\n",
    "            skip_bigram_abc[(word, coll, 'freq')] = sum(c)\n",
    "            skip_bigram_abc[(word, coll, 'spread')] = ((sum([x**2 for x in c]) - 2*c_bar*sum(c) + 2*max_distance*c_bar**2) / (2 * max_distance))**(0.5)\n",
    "            count.append(sum(c))\n",
    "        skip_bigram_abc[(word, 'avg_freq')] = np.mean(count)\n",
    "        skip_bigram_abc[(word, 'dev')] = np.std(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output 格式不拘，主要會看搭配詞 (包含距離、count) 及對應的 ngram\n",
    "- 以 role-n 這個 head word 舉例，擷取出的搭配詞有18個\n",
    "- 依 count 高低排序印出的結果如下圖～"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "k0 = 1\n",
    "U0 = 10\n",
    "k1 = 1\n",
    "\n",
    "def skip_bigram_filter(skip_bigram_info, skip_bigram_abc):\n",
    "    cc = defaultdict(lambda: [])\n",
    "    for word, vals in skip_bigram_info.items():\n",
    "        f = skip_bigram_abc[(word, 'avg_freq')]\n",
    "        for coll, val in vals.items():\n",
    "            if skip_bigram_abc[(word, 'dev')]-0 < 1E-6:\n",
    "                strength = 0\n",
    "            else:\n",
    "                strength = (skip_bigram_abc[(word, coll, 'freq')] - f) / skip_bigram_abc[(word, 'dev')]\n",
    "            if strength < k0:\n",
    "                continue\n",
    "            spread = skip_bigram_abc[(word, coll, 'spread')]\n",
    "            if spread < U0:\n",
    "                continue\n",
    "            c_bar = sum(val.values()) / (2*max_distance)\n",
    "            peak = c_bar + k1 * math.sqrt(spread)\n",
    "            for dist, count in val.items():\n",
    "                if count >= peak:\n",
    "                    cc[word].append((coll, dist, strength, spread, peak, count))\n",
    "    return cc\n",
    "\n",
    "cc = skip_bigram_filter(skipBigramDistance, skip_bigram_abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "def word_coll(word):\n",
    "    sort_by_f = sorted(cc[word], key=lambda tup: tup[5], reverse = True)\n",
    "    collocations_df = pandas.DataFrame(sort_by_f,\n",
    "                                   columns = ['collocate', 'distance', 'strength', 'spread', 'peak', 'p'])\n",
    "    return collocations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_coll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-773c23b36dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_coll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'advice-n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_coll' is not defined"
     ]
    }
   ],
   "source": [
    "word_coll('advice-n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "質能方程 $E = mc^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

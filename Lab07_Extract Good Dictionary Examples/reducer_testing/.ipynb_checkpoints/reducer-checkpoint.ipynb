{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducer 要計分\n",
    "- 去算skipbigram 所有的例句，哪個分數最高 <br>\n",
    "For 句子 in each key group of (Word, Col, Dist) <br>\n",
    "  Compute Score(S) <br>\n",
    "  = location of Word 字越後面越重要<br>\n",
    "  – #(words ∈ S & ∈/ HiFreWords) <br>\n",
    "  – #(words ∈ S & words ∈ PRONS) <br>\n",
    "Find S* with the maximum value of Score Output Word Col <tab> S*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, sys\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def tokens(str1): return re.findall('[a-z]+', str1.lower())\n",
    "\n",
    "def high_freq_words():\n",
    "    word_list = set()\n",
    "    for line in open('HiFreWords','r'):\n",
    "        for word in line.split('\\t'):\n",
    "            word_list.add(word)\n",
    "    return word_list\n",
    "            \n",
    "high_freq_list = high_freq_words()\n",
    "\n",
    "def pron_words():\n",
    "    pron_list = set()\n",
    "    for pron in open('prons.txt','r'):\n",
    "        pron_list.add(pron.strip())\n",
    "    return pron_list\n",
    "\n",
    "pron_list = pron_words()\n",
    "\n",
    "def compute_score(word, sentence):\n",
    "    sent = tokens(sentence)\n",
    "    word_loc = sent.index(word) + 1\n",
    "    not_high_freq = 0\n",
    "    prons = 0\n",
    "    for word in sent:\n",
    "        if word not in high_freq_list: not_high_freq += 1\n",
    "        if word in pron_list: prons += 1\n",
    "    return (word_loc - not_high_freq - prons)\n",
    "\n",
    "collocation_sentences = defaultdict(lambda:[])\n",
    "\n",
    "for line in open('mapper_result.txt','r'):\n",
    "    row = line.split('\\t')\n",
    "    collocation = tuple(row[0].split('_'))\n",
    "    sentence = row[1]\n",
    "    collocation_sentences[collocation].append(sentence)\n",
    "\n",
    "output_reducer_file = open('reducer_result.txt', 'a')    \n",
    "\n",
    "for key, values in collocation_sentences.items():\n",
    "    w_c_d = key[0] + '_' + key[1] + '_' + key[2]\n",
    "    first_item = w_c_d + '\\t' + values[0]\n",
    "    first_score = compute_score(key[0], values[0])\n",
    "    max_element = (first_item, first_score)\n",
    "    for sent in values[1:]:\n",
    "        item = w_c_d + '\\t' + sent\n",
    "        score = compute_score(key[0], sent)\n",
    "        if max_element[1] < score:\n",
    "            max_element = (item, score)  \n",
    "    output_reducer_file.write(max_element[0])  \n",
    "\n",
    "output_reducer_file.close()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaa\n"
     ]
    }
   ],
   "source": [
    "print('aaaaaAAaaa\\n'.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainable Artificial Intelligence\n",
    "- Correct the pattern using Noisy Channel Model\n",
    "\n",
    "\n",
    "- Right and Wrong:\n",
    "    - They **discussed about the issues**. (Wrong)\n",
    "    - They **discussed the issue**. (Right)\n",
    "    - Explanation For discuss, **use V n not V about n**\n",
    "\n",
    "\n",
    "- Step:\n",
    "    - Parse sentence\n",
    "    - Identify in/correct patterns (i.e., V about n): \n",
    "    - Correct the pattern using Noisy Channel Model\n",
    "        - V n → V about n\n",
    "    - Compute Lexical Language Model\n",
    "        - discuss: V n, V wh-to-inf, V n w,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 產生 pattern 比較組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cmd_line(line):\n",
    "    try:\n",
    "        output = subprocess.check_output(line, shell=True)\n",
    "        print(output)\n",
    "    except subprocess.CalledProcessError:\n",
    "        print('Exception handled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "產生了 wong.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n"
     ]
    }
   ],
   "source": [
    "cmd_line('cat ef_train.src.tagged.txt | python3 grampat.py >> wrong.txt ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "產生了 wong.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n"
     ]
    }
   ],
   "source": [
    "cmd_line('cat ef_train.tgt.tagged.txt | python3 grampat.py >> correct.txt ')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0\tLEAVE\tV n\tcould n't leave an answer\tBut I could n't leave an answer for you ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_pos(sent1, sent2):\n",
    "    lst = sent1.split()\n",
    "    sublst = sent2.split()\n",
    "    if len(lst) < len(sublst):\n",
    "        lst, sublst = sublst, lst\n",
    "    count = 0\n",
    "    n = len(sublst)\n",
    "    for i in range(len(lst)):\n",
    "        for j in range(n):\n",
    "            if lst[i] == sublst[j]:\n",
    "                count += 1\n",
    "            if count == n:\n",
    "                return i - n + 1\n",
    "    return -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "#{0:{(Verb,position):pattern, (Verb,position):pattern, ..},}\n",
    "\n",
    "def generate_filter_data(file):\n",
    "    \n",
    "    sen_dict = defaultdict(lambda: [])\n",
    "\n",
    "    for line in file:\n",
    "        id, verb, pat, seg, sen = line.strip('\\n').split('\\t')\n",
    "        position = pattern_pos(sen, seg)\n",
    "        sen_dict[id].append((verb,position,pat))\n",
    "    \n",
    "    return sen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_dict = generate_filter_data(open('wrong.txt','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_dict = generate_filter_data(open('correct.txt','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_dict = defaultdict(lambda: defaultdict(lambda:0))\n",
    "\n",
    "for id, correct in correct_dict.items():\n",
    "    wrong = wrong_dict[id]\n",
    "    for c in correct:\n",
    "        c_verb, c_position, c_pat = c\n",
    "        for w in wrong:\n",
    "            w_verb, w_position, w_pat = w\n",
    "            '''\n",
    "            correcting conditions:\n",
    "             1. same verb\n",
    "             2. seg start position is allowed in 3 distance\n",
    "             3. different gramma\n",
    "             4. avoid matching wrong \n",
    "            '''  \n",
    "            if (c_verb == w_verb) and (abs(c_position - w_position) <=3) and (c_pat != w_pat) and c not in wrong:\n",
    "                corrected_dict[(c_verb, w_pat)][c_pat] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1063, 182, 69, 55, 15, 15, 19, 10, 6, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "def corrected_amount_counter(_dict ,amount):\n",
    "    total = 0\n",
    "    for v in list(_dict.values().values()):\n",
    "        if v == amount:\n",
    "            total = total + 1\n",
    "    return total\n",
    "\n",
    "N_amount = [ 0 if amount == 0 else corrected_amount_counter(corrected_dict ,amount) for amount in range(12) ]\n",
    "print(N_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth(count, r=10):\n",
    "    if count <= r:\n",
    "        return (count+1)*N_amount[count+1]/N_amount[count]\n",
    "    else:\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.25"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Pedit(verb, pat):\n",
    "    key = '%s, %s' % (verb, pat)\n",
    "    if (w,c) not in count:\n",
    "        if c not in correct:\n",
    "            return 10**(-20) # 為避免分母為0，遇到這種就直接回傳一個很小的數字\n",
    "        return smooth(0)/correct[c]\n",
    "    else:\n",
    "        return smooth(count[(w,c)])/correct[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Pedit(verb, w):\n",
    "    candidates = {}\n",
    "    key = '%s, %s' % (verb, w)\n",
    "    language_model_smooth = sum(language_model[key].values()) + len(language_model[key].values())\n",
    "    if key in language_model:\n",
    "        for candidate, count in language_model[key].items():\n",
    "            language_model_prob = (count + 1) / language_model_smooth\n",
    "\n",
    "            noisy_channel_smooth = len(noisy_channel[w]) + noisy_channel[w]['COUNT']\n",
    "            noisy_channel_prob = (noisy_channel[w][candidate] + 1) / noisy_channel_smooth\n",
    "\n",
    "            candidate_prob = language_model_prob * noisy_channel_prob\n",
    "            candidates[candidate] = candidate_prob\n",
    "\n",
    "        best_candidate, prob = max(candidates.items(), key=operator.itemgetter(1))\n",
    "        return best_candidate, prob\n",
    "    else:\n",
    "        return key\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
